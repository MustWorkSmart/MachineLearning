{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747960270247,
     "user": {
      "displayName": "Folsom Chess Club",
      "userId": "01815618327063108113"
     },
     "user_tz": 420
    },
    "id": "ZFfWLMRtKgxY",
    "outputId": "020ca709-897a-45bc-f94f-f7291b745c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHigh-level summary:\\nAGENTS takes ACTIONS in the ENV which will give REWARDS(or penalties) based on the corresponding STATE/ACTION\\n\\nBackground info:\\nstate - \"state\" refers to a snapshot of the environment at a given time, while \"environment\" encompasses the entire system or context in which an agent operates\\n\\nagent - is Deep NN here, takes state and action(*) as inputs, then outputs/predicts the corresponding optimal Q-value; this is done through “value learning” (vs “policy learning”) below\\n(*) alternatively (in the implementation below for cartpole which got only 2 possible actions - left or right): action is NOT an input, and the Deep NN will output the corresponding Q-value for each possible action\\n -> during training, the “actual” action taken may or may NOT be the action which results in the highest Q-value; explore vs exploit, see hyper-parameters epsilon/epsilon_decay\\n\\nProcess:\\nusing “state” from the ENV, either explore or exploit [DQNAgent’s act()], DQNAgent provides “action” to the ENV -> ENV then provides “reward, next_state, done”\\n.. the DQNAgent saves this state/action/reward/next_state/done combo into its memory, which will be randomly sampled to train its DNN model\\n.. during training (using mse loss function), the target is  “reward + gamma * (Q-value from model_prediction using next_state for the corresponding next_action which resulted in the highest Q-value)” .. as the agent\\'s policy(*) here is to choose the action with the highest Q-value for a given state\\n(*) policy, pi(s), takes state as input and action is the output\\n\\nQ-value from the Q-function is the total expected reward and discounted (see gamma, the discount factor) future rewards for a certain state and action\\n\\nQ-values of the actions not taken are NOT updated - When an action is not taken, the Q-value for that state-action pair is not updated during the current iteration. The Q-value for the action actually taken is updated based on the reward received and the maximum Q-value of the next state. If the agent is exploring and randomly chooses an action, the Q-values of the actions not taken are still relevant for future exploitation.\\n\\nGamma (0 to 1) refers to the discount factor - It determines how much an agent values future rewards compared to immediate rewards. A higher gamma (closer to 1) means the agent prioritizes long-term rewards, while a lower gamma (closer to 0) emphasizes immediate gains.\\n\\nDiscounted total rewards - theoretically including all current and future rewards, up to infinity, implementation below including only the immediate next reward expected\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinforcement Learning\n",
    "# Deep Q Networks - DQN (used for the cartpole scenario below where action space is discrete and small)\n",
    "\n",
    "'''\n",
    "High-level summary:\n",
    "AGENTS takes ACTIONS in the ENV which will give REWARDS(or penalties) based on the corresponding STATE/ACTION\n",
    "\n",
    "Background info:\n",
    "state - \"state\" refers to a snapshot of the environment at a given time, while \"environment\" encompasses the entire system or context in which an agent operates\n",
    "\n",
    "agent - is Deep NN here, takes state and action(*) as inputs, then outputs/predicts the corresponding optimal Q-value; this is done through “value learning” (vs “policy learning”) below\n",
    "(*) alternatively (in the implementation below for cartpole which got only 2 possible actions - left or right): action is NOT an input, and the Deep NN will output the corresponding Q-value for each possible action\n",
    " -> during training, the “actual” action taken may or may NOT be the action which results in the highest Q-value; explore vs exploit, see hyper-parameters epsilon/epsilon_decay\n",
    "\n",
    "Process:\n",
    "using “state” from the ENV, either explore or exploit [DQNAgent’s act()], DQNAgent provides “action” to the ENV -> ENV then provides “reward, next_state, done”\n",
    ".. the DQNAgent saves this state/action/reward/next_state/done combo into its memory, which will be randomly sampled to train its DNN model\n",
    ".. during training (using mse loss function), the target is  “reward + gamma * (Q-value from model_prediction using next_state for the corresponding next_action which resulted in the highest Q-value)” .. as the agent's policy(*) here is to choose the action with the highest Q-value for a given state\n",
    "(*) policy, pi(s), takes state as input and action is the output\n",
    "\n",
    "Q-value from the Q-function is the total expected reward and discounted (see gamma, the discount factor) future rewards for a certain state and action\n",
    "\n",
    "Q-values of the actions not taken are NOT updated - When an action is not taken, the Q-value for that state-action pair is not updated during the current iteration. The Q-value for the action actually taken is updated based on the reward received and the maximum Q-value of the next state. If the agent is exploring and randomly chooses an action, the Q-values of the actions not taken are still relevant for future exploitation.\n",
    "\n",
    "Gamma (0 to 1) refers to the discount factor - It determines how much an agent values future rewards compared to immediate rewards. A higher gamma (closer to 1) means the agent prioritizes long-term rewards, while a lower gamma (closer to 0) emphasizes immediate gains.\n",
    "\n",
    "Discounted total rewards - theoretically including all current and future rewards, up to infinity, implementation below including only the immediate next reward expected\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #this does NOT suppress the many *ms/step logs from keras, see verbose=0 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9904,
     "status": "ok",
     "timestamp": 1747960280147,
     "user": {
      "displayName": "Folsom Chess Club",
      "userId": "01815618327063108113"
     },
     "user_tz": 420
    },
    "id": "y6JzjI6I5X_I",
    "outputId": "15e22858-7659-4974-abc8-e69300d4da78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.21.3\n",
      "gym==0.26.2\n",
      "gym-notices==0.0.8\n",
      "gymnasium==1.1.1\n",
      "tensorflow==2.10.0\n",
      "tensorflow-estimator==2.10.0\n",
      "tensorflow-io-gcs-filesystem==0.31.0\n",
      "keras==2.10.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "!pip freeze | grep numpy\n",
    "!pip freeze | grep gym\n",
    "!pip freeze | grep tensorflow\n",
    "'''\n",
    "!pip freeze | findstr numpy\n",
    "!pip freeze | findstr gym\n",
    "!pip freeze | findstr tensorflow\n",
    "!pip freeze | findstr keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\\n# Anything above 2.10 is not supported on the GPU on Windows Native\\npython -m pip install \"tensorflow<2.11\"\\n# Verify the installation:\\npython -c \"import tensorflow as tf; print(tf.config.list_physical_devices(\\'GPU\\'))\"\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downgraded to tensorflow 2.10 in order to use GPU, newer TF versions have issues with GPU, hence NOT using these:\n",
    "'''\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.api.layers import Dense\n",
    "from keras.optimizers import Nadam\n",
    "'''\n",
    "\n",
    "# from https://www.tensorflow.org/install/pip\n",
    "'''\n",
    "conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "# Anything above 2.10 is not supported on the GPU on Windows Native\n",
    "python -m pip install \"tensorflow<2.11\"\n",
    "# Verify the installation:\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E7C9_lB1iHNN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "#import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import os # for creating directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1_GzakuiHNV"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set the logging level to suppress \"ms/step\" messages\n",
    "#logging.getLogger(\"gymnasium\").setLevel(logging.CRITICAL) #this does NOT help though\n",
    "#logging.getLogger(\"gym\").setLevel(logging.CRITICAL) #this does NOT help though\n",
    "logging.getLogger(\"openai\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_2sPz36XiHNW"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0') # initialise environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747960286933,
     "user": {
      "displayName": "Folsom Chess Club",
      "userId": "01815618327063108113"
     },
     "user_tz": 420
    },
    "id": "cK0V5UQXiHNd",
    "outputId": "4e6067e9-48d9-435c-b1f1-bd35685c9732"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size = env.observation_space.shape[0]\n",
    "state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1747960286969,
     "user": {
      "displayName": "Folsom Chess Club",
      "userId": "01815618327063108113"
     },
     "user_tz": 420
    },
    "id": "T3ad_bEGiHNm",
    "outputId": "86d42641-4dfc-44e2-a1fa-12ffa4857199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "i0JRMP1diHNr"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8DDZrj7iiHNw"
   },
   "outputs": [],
   "source": [
    "n_episodes = 1000 # n games we want agent to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dF34tJugiHN3"
   },
   "outputs": [],
   "source": [
    "output_dir = 'model_output/cartpole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PlV1yezViHN_"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beLpgy0SiHOF"
   },
   "source": [
    "#### Define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2DiQrKSxiHOH"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000) # this double-ended queue vs traditional list: need to compare given the order is NOT relevant here, usage is just random sampling\n",
    "        self.gamma = 0.95 # discount rate: agent takes future actions into account in addition to the immediate one, but discounted at this rate per time period\n",
    "        self.epsilon = 1.0 # exploration rate: how much to act randomly (1.0 -> starting 100% randomly); more initially than later due to epsilon decay\n",
    "        self.epsilon_decay = 0.995 # decrease number of random explorations as the agent's performance (hopefully) improves over time\n",
    "        self.epsilon_min = 0.01 # minimum amount of random exploration permitted\n",
    "        self.learning_rate = 0.001 # rate at which NN adjusts models parameters via SGD to reduce cost\n",
    "        self.model = self._build_model() # private method\n",
    "\n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu',\n",
    "                        input_dim=self.state_size)) # 1st hidden layer; states as input\n",
    "        model.add(Dense(32, activation='relu')) # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse', optimizer=Nadam(learning_rate=self.learning_rate))\n",
    "                      #optimizer=Nadam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # list of previous experiences, enabling re-training later\n",
    "\n",
    "    def train(self, batch_size): # method that trains NN with experiences sampled from memory\n",
    "        minibatch = random.sample(self.memory, batch_size) # sample a minibatch from memory\n",
    "        for state, action, reward, next_state, done in minibatch: # extract data for each minibatch sample\n",
    "            target = reward # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward\n",
    "            if not done: # if not done, then predict future discounted reward\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state, verbose=0)[0]))\n",
    "                # target Q-value = reward + (discount rate gamma) * (maximum target Q-value based on future state s' and future action a')\n",
    "            target_f = self.model.predict(state, verbose=0) # approximately map current state to future discounted reward\n",
    "            target_f[0][action] = target #updating ONLY the Q-value for the action taken above, other Q-values (for the actions NOT taken) staying the same\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0) # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon: # if acting randomly, take random action\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0) # if not acting randomly, predict reward value based on current state\n",
    "        return np.argmax(act_values[0]) # pick the action that will give the highest reward (in the case here, the action is: go left or right)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z5loBrJiHON"
   },
   "source": [
    "#### Interact with environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1747960287174,
     "user": {
      "displayName": "Folsom Chess Club",
      "userId": "01815618327063108113"
     },
     "user_tz": 420
    },
    "id": "7r7dDq-0iHOO",
    "outputId": "da1f8c85-596f-40eb-8a46-1bd5e690daf4"
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_size, action_size) # initialise agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H2v8IrqviHOS",
    "outputId": "46f50e50-4cd7-477d-8ac2-d454999787b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/1000, score: 36, epsilon: 1.0\n",
      "episode: 2/1000, score: 21, epsilon: 0.99\n",
      "episode: 3/1000, score: 13, epsilon: 0.99\n",
      "episode: 4/1000, score: 42, epsilon: 0.99\n",
      "episode: 5/1000, score: 20, epsilon: 0.98\n",
      "episode: 6/1000, score: 10, epsilon: 0.98\n",
      "episode: 7/1000, score: 37, epsilon: 0.97\n",
      "episode: 8/1000, score: 14, epsilon: 0.97\n",
      "episode: 9/1000, score: 13, epsilon: 0.96\n",
      "episode: 10/1000, score: 12, epsilon: 0.96\n",
      "episode: 11/1000, score: 15, epsilon: 0.95\n",
      "episode: 12/1000, score: 14, epsilon: 0.95\n",
      "episode: 13/1000, score: 15, epsilon: 0.94\n",
      "episode: 14/1000, score: 18, epsilon: 0.94\n",
      "episode: 15/1000, score: 22, epsilon: 0.93\n",
      "episode: 16/1000, score: 39, epsilon: 0.93\n",
      "episode: 17/1000, score: 13, epsilon: 0.92\n",
      "episode: 18/1000, score: 24, epsilon: 0.92\n",
      "episode: 19/1000, score: 29, epsilon: 0.91\n",
      "episode: 20/1000, score: 14, epsilon: 0.91\n",
      "episode: 21/1000, score: 15, epsilon: 0.9\n",
      "episode: 22/1000, score: 32, epsilon: 0.9\n",
      "episode: 23/1000, score: 13, epsilon: 0.9\n",
      "episode: 24/1000, score: 9, epsilon: 0.89\n",
      "episode: 25/1000, score: 19, epsilon: 0.89\n",
      "episode: 26/1000, score: 10, epsilon: 0.88\n",
      "episode: 27/1000, score: 10, epsilon: 0.88\n",
      "episode: 28/1000, score: 11, epsilon: 0.87\n",
      "episode: 29/1000, score: 112, epsilon: 0.87\n",
      "episode: 30/1000, score: 27, epsilon: 0.86\n",
      "episode: 31/1000, score: 13, epsilon: 0.86\n",
      "episode: 32/1000, score: 17, epsilon: 0.86\n",
      "episode: 33/1000, score: 9, epsilon: 0.85\n",
      "episode: 34/1000, score: 24, epsilon: 0.85\n",
      "episode: 35/1000, score: 30, epsilon: 0.84\n",
      "episode: 36/1000, score: 17, epsilon: 0.84\n",
      "episode: 37/1000, score: 15, epsilon: 0.83\n",
      "episode: 38/1000, score: 26, epsilon: 0.83\n",
      "episode: 39/1000, score: 56, epsilon: 0.83\n",
      "episode: 40/1000, score: 16, epsilon: 0.82\n",
      "episode: 41/1000, score: 12, epsilon: 0.82\n",
      "episode: 42/1000, score: 13, epsilon: 0.81\n",
      "episode: 43/1000, score: 12, epsilon: 0.81\n",
      "episode: 44/1000, score: 16, epsilon: 0.81\n",
      "episode: 45/1000, score: 12, epsilon: 0.8\n",
      "episode: 46/1000, score: 16, epsilon: 0.8\n",
      "episode: 47/1000, score: 20, epsilon: 0.79\n",
      "episode: 48/1000, score: 47, epsilon: 0.79\n",
      "episode: 49/1000, score: 18, epsilon: 0.79\n",
      "episode: 50/1000, score: 17, epsilon: 0.78\n",
      "episode: 51/1000, score: 16, epsilon: 0.78\n",
      "episode: 52/1000, score: 12, epsilon: 0.77\n",
      "episode: 53/1000, score: 45, epsilon: 0.77\n",
      "episode: 54/1000, score: 9, epsilon: 0.77\n",
      "episode: 55/1000, score: 13, epsilon: 0.76\n",
      "episode: 56/1000, score: 21, epsilon: 0.76\n",
      "episode: 57/1000, score: 11, epsilon: 0.76\n",
      "episode: 58/1000, score: 12, epsilon: 0.75\n",
      "episode: 59/1000, score: 36, epsilon: 0.75\n",
      "episode: 60/1000, score: 12, epsilon: 0.74\n",
      "episode: 61/1000, score: 9, epsilon: 0.74\n",
      "episode: 62/1000, score: 30, epsilon: 0.74\n",
      "episode: 63/1000, score: 36, epsilon: 0.73\n",
      "episode: 64/1000, score: 16, epsilon: 0.73\n",
      "episode: 65/1000, score: 14, epsilon: 0.73\n",
      "episode: 66/1000, score: 10, epsilon: 0.72\n",
      "episode: 67/1000, score: 13, epsilon: 0.72\n",
      "episode: 68/1000, score: 13, epsilon: 0.71\n",
      "episode: 69/1000, score: 18, epsilon: 0.71\n",
      "episode: 70/1000, score: 10, epsilon: 0.71\n",
      "episode: 71/1000, score: 7, epsilon: 0.7\n",
      "episode: 72/1000, score: 11, epsilon: 0.7\n",
      "episode: 73/1000, score: 8, epsilon: 0.7\n",
      "episode: 74/1000, score: 14, epsilon: 0.69\n",
      "episode: 75/1000, score: 8, epsilon: 0.69\n",
      "episode: 76/1000, score: 10, epsilon: 0.69\n",
      "episode: 77/1000, score: 14, epsilon: 0.68\n",
      "episode: 78/1000, score: 18, epsilon: 0.68\n",
      "episode: 79/1000, score: 11, epsilon: 0.68\n",
      "episode: 80/1000, score: 12, epsilon: 0.67\n",
      "episode: 81/1000, score: 10, epsilon: 0.67\n",
      "episode: 82/1000, score: 10, epsilon: 0.67\n",
      "episode: 83/1000, score: 18, epsilon: 0.66\n",
      "episode: 84/1000, score: 8, epsilon: 0.66\n",
      "episode: 85/1000, score: 21, epsilon: 0.66\n",
      "episode: 86/1000, score: 9, epsilon: 0.65\n",
      "episode: 87/1000, score: 12, epsilon: 0.65\n",
      "episode: 88/1000, score: 17, epsilon: 0.65\n",
      "episode: 89/1000, score: 16, epsilon: 0.64\n",
      "episode: 90/1000, score: 9, epsilon: 0.64\n",
      "episode: 91/1000, score: 12, epsilon: 0.64\n",
      "episode: 92/1000, score: 10, epsilon: 0.63\n",
      "episode: 93/1000, score: 18, epsilon: 0.63\n",
      "episode: 94/1000, score: 9, epsilon: 0.63\n",
      "episode: 95/1000, score: 8, epsilon: 0.62\n",
      "episode: 96/1000, score: 10, epsilon: 0.62\n",
      "episode: 97/1000, score: 9, epsilon: 0.62\n",
      "episode: 98/1000, score: 18, epsilon: 0.61\n",
      "episode: 99/1000, score: 10, epsilon: 0.61\n",
      "episode: 100/1000, score: 9, epsilon: 0.61\n",
      "episode: 101/1000, score: 7, epsilon: 0.61\n",
      "episode: 102/1000, score: 7, epsilon: 0.6\n",
      "episode: 103/1000, score: 11, epsilon: 0.6\n",
      "episode: 104/1000, score: 17, epsilon: 0.6\n",
      "episode: 105/1000, score: 12, epsilon: 0.59\n",
      "episode: 106/1000, score: 10, epsilon: 0.59\n",
      "episode: 107/1000, score: 12, epsilon: 0.59\n",
      "episode: 108/1000, score: 11, epsilon: 0.58\n",
      "episode: 109/1000, score: 10, epsilon: 0.58\n",
      "episode: 110/1000, score: 14, epsilon: 0.58\n",
      "episode: 111/1000, score: 18, epsilon: 0.58\n",
      "episode: 112/1000, score: 12, epsilon: 0.57\n",
      "episode: 113/1000, score: 12, epsilon: 0.57\n",
      "episode: 114/1000, score: 16, epsilon: 0.57\n",
      "episode: 115/1000, score: 32, epsilon: 0.56\n",
      "episode: 116/1000, score: 9, epsilon: 0.56\n",
      "episode: 117/1000, score: 11, epsilon: 0.56\n",
      "episode: 118/1000, score: 17, epsilon: 0.56\n",
      "episode: 119/1000, score: 7, epsilon: 0.55\n",
      "episode: 120/1000, score: 10, epsilon: 0.55\n",
      "episode: 121/1000, score: 10, epsilon: 0.55\n",
      "episode: 122/1000, score: 12, epsilon: 0.55\n",
      "episode: 123/1000, score: 13, epsilon: 0.54\n",
      "episode: 124/1000, score: 11, epsilon: 0.54\n",
      "episode: 125/1000, score: 8, epsilon: 0.54\n",
      "episode: 126/1000, score: 16, epsilon: 0.53\n",
      "episode: 127/1000, score: 13, epsilon: 0.53\n",
      "episode: 128/1000, score: 9, epsilon: 0.53\n",
      "episode: 129/1000, score: 13, epsilon: 0.53\n",
      "episode: 130/1000, score: 10, epsilon: 0.52\n",
      "episode: 131/1000, score: 14, epsilon: 0.52\n",
      "episode: 132/1000, score: 13, epsilon: 0.52\n",
      "episode: 133/1000, score: 9, epsilon: 0.52\n",
      "episode: 134/1000, score: 10, epsilon: 0.51\n",
      "episode: 135/1000, score: 17, epsilon: 0.51\n",
      "episode: 136/1000, score: 10, epsilon: 0.51\n",
      "episode: 137/1000, score: 20, epsilon: 0.51\n",
      "episode: 138/1000, score: 7, epsilon: 0.5\n",
      "episode: 139/1000, score: 12, epsilon: 0.5\n",
      "episode: 140/1000, score: 29, epsilon: 0.5\n",
      "episode: 141/1000, score: 10, epsilon: 0.5\n",
      "episode: 142/1000, score: 11, epsilon: 0.49\n",
      "episode: 143/1000, score: 9, epsilon: 0.49\n",
      "episode: 144/1000, score: 11, epsilon: 0.49\n",
      "episode: 145/1000, score: 13, epsilon: 0.49\n",
      "episode: 146/1000, score: 24, epsilon: 0.48\n",
      "episode: 147/1000, score: 12, epsilon: 0.48\n",
      "episode: 148/1000, score: 12, epsilon: 0.48\n",
      "episode: 149/1000, score: 9, epsilon: 0.48\n",
      "episode: 150/1000, score: 15, epsilon: 0.47\n",
      "episode: 151/1000, score: 16, epsilon: 0.47\n",
      "episode: 152/1000, score: 12, epsilon: 0.47\n",
      "episode: 153/1000, score: 19, epsilon: 0.47\n",
      "episode: 154/1000, score: 11, epsilon: 0.46\n",
      "episode: 155/1000, score: 15, epsilon: 0.46\n",
      "episode: 156/1000, score: 16, epsilon: 0.46\n",
      "episode: 157/1000, score: 13, epsilon: 0.46\n",
      "episode: 158/1000, score: 7, epsilon: 0.46\n",
      "episode: 159/1000, score: 41, epsilon: 0.45\n",
      "episode: 160/1000, score: 27, epsilon: 0.45\n",
      "episode: 161/1000, score: 65, epsilon: 0.45\n",
      "episode: 162/1000, score: 26, epsilon: 0.45\n",
      "episode: 163/1000, score: 27, epsilon: 0.44\n",
      "episode: 164/1000, score: 26, epsilon: 0.44\n",
      "episode: 165/1000, score: 17, epsilon: 0.44\n",
      "episode: 166/1000, score: 24, epsilon: 0.44\n",
      "episode: 167/1000, score: 25, epsilon: 0.44\n",
      "episode: 168/1000, score: 28, epsilon: 0.43\n",
      "episode: 169/1000, score: 37, epsilon: 0.43\n",
      "episode: 170/1000, score: 33, epsilon: 0.43\n",
      "episode: 171/1000, score: 18, epsilon: 0.43\n",
      "episode: 172/1000, score: 21, epsilon: 0.42\n",
      "episode: 173/1000, score: 15, epsilon: 0.42\n",
      "episode: 174/1000, score: 12, epsilon: 0.42\n",
      "episode: 175/1000, score: 14, epsilon: 0.42\n",
      "episode: 176/1000, score: 16, epsilon: 0.42\n",
      "episode: 177/1000, score: 15, epsilon: 0.41\n",
      "episode: 178/1000, score: 19, epsilon: 0.41\n",
      "episode: 179/1000, score: 17, epsilon: 0.41\n",
      "episode: 180/1000, score: 39, epsilon: 0.41\n",
      "episode: 181/1000, score: 18, epsilon: 0.41\n",
      "episode: 182/1000, score: 28, epsilon: 0.4\n",
      "episode: 183/1000, score: 82, epsilon: 0.4\n",
      "episode: 184/1000, score: 75, epsilon: 0.4\n",
      "episode: 185/1000, score: 31, epsilon: 0.4\n",
      "episode: 186/1000, score: 24, epsilon: 0.4\n",
      "episode: 187/1000, score: 35, epsilon: 0.39\n",
      "episode: 188/1000, score: 39, epsilon: 0.39\n",
      "episode: 189/1000, score: 19, epsilon: 0.39\n",
      "episode: 190/1000, score: 20, epsilon: 0.39\n",
      "episode: 191/1000, score: 21, epsilon: 0.39\n",
      "episode: 192/1000, score: 62, epsilon: 0.38\n",
      "episode: 193/1000, score: 53, epsilon: 0.38\n",
      "episode: 194/1000, score: 74, epsilon: 0.38\n",
      "episode: 195/1000, score: 23, epsilon: 0.38\n",
      "episode: 196/1000, score: 65, epsilon: 0.38\n",
      "episode: 197/1000, score: 27, epsilon: 0.37\n",
      "episode: 198/1000, score: 56, epsilon: 0.37\n",
      "episode: 199/1000, score: 49, epsilon: 0.37\n",
      "episode: 200/1000, score: 37, epsilon: 0.37\n",
      "episode: 201/1000, score: 52, epsilon: 0.37\n",
      "episode: 202/1000, score: 45, epsilon: 0.37\n",
      "episode: 203/1000, score: 85, epsilon: 0.36\n",
      "episode: 204/1000, score: 41, epsilon: 0.36\n",
      "episode: 205/1000, score: 21, epsilon: 0.36\n",
      "episode: 206/1000, score: 36, epsilon: 0.36\n",
      "episode: 207/1000, score: 15, epsilon: 0.36\n",
      "episode: 208/1000, score: 18, epsilon: 0.35\n",
      "episode: 209/1000, score: 79, epsilon: 0.35\n",
      "episode: 210/1000, score: 35, epsilon: 0.35\n",
      "episode: 211/1000, score: 41, epsilon: 0.35\n",
      "episode: 212/1000, score: 54, epsilon: 0.35\n",
      "episode: 213/1000, score: 43, epsilon: 0.35\n",
      "episode: 214/1000, score: 36, epsilon: 0.34\n",
      "episode: 215/1000, score: 20, epsilon: 0.34\n",
      "episode: 216/1000, score: 21, epsilon: 0.34\n",
      "episode: 217/1000, score: 31, epsilon: 0.34\n",
      "episode: 218/1000, score: 32, epsilon: 0.34\n",
      "episode: 219/1000, score: 36, epsilon: 0.34\n",
      "episode: 220/1000, score: 66, epsilon: 0.33\n",
      "episode: 221/1000, score: 51, epsilon: 0.33\n",
      "episode: 222/1000, score: 33, epsilon: 0.33\n",
      "episode: 223/1000, score: 69, epsilon: 0.33\n",
      "episode: 224/1000, score: 38, epsilon: 0.33\n",
      "episode: 225/1000, score: 31, epsilon: 0.33\n",
      "episode: 226/1000, score: 30, epsilon: 0.32\n",
      "episode: 227/1000, score: 35, epsilon: 0.32\n",
      "episode: 228/1000, score: 14, epsilon: 0.32\n",
      "episode: 229/1000, score: 34, epsilon: 0.32\n",
      "episode: 230/1000, score: 27, epsilon: 0.32\n",
      "episode: 231/1000, score: 37, epsilon: 0.32\n",
      "episode: 232/1000, score: 30, epsilon: 0.31\n",
      "episode: 233/1000, score: 18, epsilon: 0.31\n",
      "episode: 234/1000, score: 41, epsilon: 0.31\n",
      "episode: 235/1000, score: 46, epsilon: 0.31\n",
      "episode: 236/1000, score: 42, epsilon: 0.31\n",
      "episode: 237/1000, score: 40, epsilon: 0.31\n",
      "episode: 238/1000, score: 25, epsilon: 0.3\n",
      "episode: 239/1000, score: 37, epsilon: 0.3\n",
      "episode: 240/1000, score: 42, epsilon: 0.3\n",
      "episode: 241/1000, score: 64, epsilon: 0.3\n",
      "episode: 242/1000, score: 17, epsilon: 0.3\n",
      "episode: 243/1000, score: 22, epsilon: 0.3\n",
      "episode: 244/1000, score: 39, epsilon: 0.3\n",
      "episode: 245/1000, score: 69, epsilon: 0.29\n",
      "episode: 246/1000, score: 18, epsilon: 0.29\n",
      "episode: 247/1000, score: 117, epsilon: 0.29\n",
      "episode: 248/1000, score: 31, epsilon: 0.29\n",
      "episode: 249/1000, score: 20, epsilon: 0.29\n",
      "episode: 250/1000, score: 46, epsilon: 0.29\n",
      "episode: 251/1000, score: 29, epsilon: 0.29\n",
      "episode: 252/1000, score: 36, epsilon: 0.28\n",
      "episode: 253/1000, score: 80, epsilon: 0.28\n",
      "episode: 254/1000, score: 74, epsilon: 0.28\n",
      "episode: 255/1000, score: 42, epsilon: 0.28\n",
      "episode: 256/1000, score: 23, epsilon: 0.28\n",
      "episode: 257/1000, score: 23, epsilon: 0.28\n",
      "episode: 258/1000, score: 110, epsilon: 0.28\n",
      "episode: 259/1000, score: 20, epsilon: 0.27\n",
      "episode: 260/1000, score: 103, epsilon: 0.27\n",
      "episode: 261/1000, score: 95, epsilon: 0.27\n",
      "episode: 262/1000, score: 20, epsilon: 0.27\n",
      "episode: 263/1000, score: 62, epsilon: 0.27\n",
      "episode: 264/1000, score: 53, epsilon: 0.27\n",
      "episode: 265/1000, score: 48, epsilon: 0.27\n",
      "episode: 266/1000, score: 59, epsilon: 0.26\n",
      "episode: 267/1000, score: 28, epsilon: 0.26\n",
      "episode: 268/1000, score: 73, epsilon: 0.26\n",
      "episode: 269/1000, score: 52, epsilon: 0.26\n",
      "episode: 270/1000, score: 138, epsilon: 0.26\n",
      "episode: 271/1000, score: 75, epsilon: 0.26\n",
      "episode: 272/1000, score: 36, epsilon: 0.26\n",
      "episode: 273/1000, score: 53, epsilon: 0.26\n",
      "episode: 274/1000, score: 34, epsilon: 0.25\n",
      "episode: 275/1000, score: 42, epsilon: 0.25\n",
      "episode: 276/1000, score: 91, epsilon: 0.25\n",
      "episode: 277/1000, score: 48, epsilon: 0.25\n",
      "episode: 278/1000, score: 41, epsilon: 0.25\n",
      "episode: 279/1000, score: 31, epsilon: 0.25\n",
      "episode: 280/1000, score: 89, epsilon: 0.25\n",
      "episode: 281/1000, score: 45, epsilon: 0.25\n",
      "episode: 282/1000, score: 17, epsilon: 0.24\n",
      "episode: 283/1000, score: 28, epsilon: 0.24\n",
      "episode: 284/1000, score: 56, epsilon: 0.24\n",
      "episode: 285/1000, score: 30, epsilon: 0.24\n",
      "episode: 286/1000, score: 30, epsilon: 0.24\n",
      "episode: 287/1000, score: 26, epsilon: 0.24\n",
      "episode: 288/1000, score: 19, epsilon: 0.24\n",
      "episode: 289/1000, score: 11, epsilon: 0.24\n",
      "episode: 290/1000, score: 34, epsilon: 0.23\n",
      "episode: 291/1000, score: 38, epsilon: 0.23\n",
      "episode: 292/1000, score: 30, epsilon: 0.23\n",
      "episode: 293/1000, score: 24, epsilon: 0.23\n",
      "episode: 294/1000, score: 61, epsilon: 0.23\n",
      "episode: 295/1000, score: 31, epsilon: 0.23\n",
      "episode: 296/1000, score: 27, epsilon: 0.23\n",
      "episode: 297/1000, score: 51, epsilon: 0.23\n",
      "episode: 298/1000, score: 23, epsilon: 0.23\n",
      "episode: 299/1000, score: 27, epsilon: 0.22\n",
      "episode: 300/1000, score: 24, epsilon: 0.22\n",
      "episode: 301/1000, score: 46, epsilon: 0.22\n",
      "episode: 302/1000, score: 91, epsilon: 0.22\n",
      "episode: 303/1000, score: 28, epsilon: 0.22\n",
      "episode: 304/1000, score: 170, epsilon: 0.22\n",
      "episode: 305/1000, score: 64, epsilon: 0.22\n",
      "episode: 306/1000, score: 37, epsilon: 0.22\n",
      "episode: 307/1000, score: 20, epsilon: 0.22\n",
      "episode: 308/1000, score: 23, epsilon: 0.21\n",
      "episode: 309/1000, score: 50, epsilon: 0.21\n",
      "episode: 310/1000, score: 31, epsilon: 0.21\n",
      "episode: 311/1000, score: 55, epsilon: 0.21\n",
      "episode: 312/1000, score: 31, epsilon: 0.21\n",
      "episode: 313/1000, score: 69, epsilon: 0.21\n",
      "episode: 314/1000, score: 39, epsilon: 0.21\n",
      "episode: 315/1000, score: 58, epsilon: 0.21\n",
      "episode: 316/1000, score: 32, epsilon: 0.21\n",
      "episode: 317/1000, score: 44, epsilon: 0.21\n",
      "episode: 318/1000, score: 24, epsilon: 0.2\n",
      "episode: 319/1000, score: 42, epsilon: 0.2\n",
      "episode: 320/1000, score: 108, epsilon: 0.2\n",
      "episode: 321/1000, score: 31, epsilon: 0.2\n",
      "episode: 322/1000, score: 80, epsilon: 0.2\n",
      "episode: 323/1000, score: 50, epsilon: 0.2\n",
      "episode: 324/1000, score: 26, epsilon: 0.2\n",
      "episode: 325/1000, score: 26, epsilon: 0.2\n",
      "episode: 326/1000, score: 65, epsilon: 0.2\n",
      "episode: 327/1000, score: 65, epsilon: 0.2\n",
      "episode: 328/1000, score: 71, epsilon: 0.19\n",
      "episode: 329/1000, score: 32, epsilon: 0.19\n",
      "episode: 330/1000, score: 42, epsilon: 0.19\n",
      "episode: 331/1000, score: 30, epsilon: 0.19\n",
      "episode: 332/1000, score: 109, epsilon: 0.19\n",
      "episode: 333/1000, score: 36, epsilon: 0.19\n",
      "episode: 334/1000, score: 21, epsilon: 0.19\n",
      "episode: 335/1000, score: 48, epsilon: 0.19\n",
      "episode: 336/1000, score: 44, epsilon: 0.19\n",
      "episode: 337/1000, score: 71, epsilon: 0.19\n",
      "episode: 338/1000, score: 36, epsilon: 0.18\n",
      "episode: 339/1000, score: 47, epsilon: 0.18\n",
      "episode: 340/1000, score: 69, epsilon: 0.18\n",
      "episode: 341/1000, score: 37, epsilon: 0.18\n",
      "episode: 342/1000, score: 44, epsilon: 0.18\n",
      "episode: 343/1000, score: 46, epsilon: 0.18\n",
      "episode: 344/1000, score: 60, epsilon: 0.18\n",
      "episode: 345/1000, score: 53, epsilon: 0.18\n",
      "episode: 346/1000, score: 14, epsilon: 0.18\n",
      "episode: 347/1000, score: 28, epsilon: 0.18\n",
      "episode: 348/1000, score: 39, epsilon: 0.18\n",
      "episode: 349/1000, score: 199, epsilon: 0.17\n",
      "episode: 350/1000, score: 49, epsilon: 0.17\n",
      "episode: 351/1000, score: 47, epsilon: 0.17\n",
      "episode: 352/1000, score: 54, epsilon: 0.17\n",
      "episode: 353/1000, score: 70, epsilon: 0.17\n",
      "episode: 354/1000, score: 48, epsilon: 0.17\n",
      "episode: 355/1000, score: 54, epsilon: 0.17\n",
      "episode: 356/1000, score: 70, epsilon: 0.17\n",
      "episode: 357/1000, score: 61, epsilon: 0.17\n",
      "episode: 358/1000, score: 28, epsilon: 0.17\n",
      "episode: 359/1000, score: 32, epsilon: 0.17\n",
      "episode: 360/1000, score: 53, epsilon: 0.17\n",
      "episode: 361/1000, score: 44, epsilon: 0.16\n",
      "episode: 362/1000, score: 40, epsilon: 0.16\n",
      "episode: 363/1000, score: 45, epsilon: 0.16\n",
      "episode: 364/1000, score: 39, epsilon: 0.16\n",
      "episode: 365/1000, score: 107, epsilon: 0.16\n",
      "episode: 366/1000, score: 41, epsilon: 0.16\n",
      "episode: 367/1000, score: 104, epsilon: 0.16\n",
      "episode: 368/1000, score: 34, epsilon: 0.16\n",
      "episode: 369/1000, score: 151, epsilon: 0.16\n",
      "episode: 370/1000, score: 55, epsilon: 0.16\n",
      "episode: 371/1000, score: 51, epsilon: 0.16\n",
      "episode: 372/1000, score: 103, epsilon: 0.16\n",
      "episode: 373/1000, score: 79, epsilon: 0.15\n",
      "episode: 374/1000, score: 102, epsilon: 0.15\n",
      "episode: 375/1000, score: 50, epsilon: 0.15\n",
      "episode: 376/1000, score: 72, epsilon: 0.15\n",
      "episode: 377/1000, score: 53, epsilon: 0.15\n",
      "episode: 378/1000, score: 57, epsilon: 0.15\n",
      "episode: 379/1000, score: 20, epsilon: 0.15\n",
      "episode: 380/1000, score: 45, epsilon: 0.15\n",
      "episode: 381/1000, score: 76, epsilon: 0.15\n",
      "episode: 382/1000, score: 98, epsilon: 0.15\n",
      "episode: 383/1000, score: 120, epsilon: 0.15\n",
      "episode: 384/1000, score: 52, epsilon: 0.15\n",
      "episode: 385/1000, score: 77, epsilon: 0.15\n",
      "episode: 386/1000, score: 45, epsilon: 0.15\n",
      "episode: 387/1000, score: 59, epsilon: 0.14\n",
      "episode: 388/1000, score: 108, epsilon: 0.14\n",
      "episode: 389/1000, score: 44, epsilon: 0.14\n",
      "episode: 390/1000, score: 42, epsilon: 0.14\n",
      "episode: 391/1000, score: 39, epsilon: 0.14\n",
      "episode: 392/1000, score: 39, epsilon: 0.14\n",
      "episode: 393/1000, score: 30, epsilon: 0.14\n",
      "episode: 394/1000, score: 62, epsilon: 0.14\n",
      "episode: 395/1000, score: 59, epsilon: 0.14\n",
      "episode: 396/1000, score: 72, epsilon: 0.14\n",
      "episode: 397/1000, score: 45, epsilon: 0.14\n",
      "episode: 398/1000, score: 46, epsilon: 0.14\n",
      "episode: 399/1000, score: 90, epsilon: 0.14\n",
      "episode: 400/1000, score: 100, epsilon: 0.14\n",
      "episode: 401/1000, score: 73, epsilon: 0.13\n",
      "episode: 402/1000, score: 153, epsilon: 0.13\n",
      "episode: 403/1000, score: 93, epsilon: 0.13\n",
      "episode: 404/1000, score: 87, epsilon: 0.13\n",
      "episode: 405/1000, score: 84, epsilon: 0.13\n",
      "episode: 406/1000, score: 72, epsilon: 0.13\n",
      "episode: 407/1000, score: 50, epsilon: 0.13\n",
      "episode: 408/1000, score: 46, epsilon: 0.13\n",
      "episode: 409/1000, score: 39, epsilon: 0.13\n",
      "episode: 410/1000, score: 59, epsilon: 0.13\n",
      "episode: 411/1000, score: 61, epsilon: 0.13\n",
      "episode: 412/1000, score: 131, epsilon: 0.13\n",
      "episode: 413/1000, score: 199, epsilon: 0.13\n",
      "episode: 414/1000, score: 113, epsilon: 0.13\n",
      "episode: 415/1000, score: 71, epsilon: 0.13\n",
      "episode: 416/1000, score: 67, epsilon: 0.12\n",
      "episode: 417/1000, score: 110, epsilon: 0.12\n",
      "episode: 418/1000, score: 69, epsilon: 0.12\n",
      "episode: 419/1000, score: 80, epsilon: 0.12\n",
      "episode: 420/1000, score: 47, epsilon: 0.12\n",
      "episode: 421/1000, score: 87, epsilon: 0.12\n",
      "episode: 422/1000, score: 66, epsilon: 0.12\n",
      "episode: 423/1000, score: 129, epsilon: 0.12\n",
      "episode: 424/1000, score: 68, epsilon: 0.12\n",
      "episode: 425/1000, score: 105, epsilon: 0.12\n",
      "episode: 426/1000, score: 115, epsilon: 0.12\n",
      "episode: 427/1000, score: 150, epsilon: 0.12\n",
      "episode: 428/1000, score: 199, epsilon: 0.12\n",
      "episode: 429/1000, score: 116, epsilon: 0.12\n",
      "episode: 430/1000, score: 199, epsilon: 0.12\n",
      "episode: 431/1000, score: 192, epsilon: 0.12\n",
      "episode: 432/1000, score: 160, epsilon: 0.12\n",
      "episode: 433/1000, score: 80, epsilon: 0.11\n",
      "episode: 434/1000, score: 199, epsilon: 0.11\n",
      "episode: 435/1000, score: 199, epsilon: 0.11\n",
      "episode: 436/1000, score: 120, epsilon: 0.11\n",
      "episode: 437/1000, score: 195, epsilon: 0.11\n",
      "episode: 438/1000, score: 199, epsilon: 0.11\n",
      "episode: 439/1000, score: 169, epsilon: 0.11\n",
      "episode: 440/1000, score: 199, epsilon: 0.11\n",
      "episode: 441/1000, score: 140, epsilon: 0.11\n",
      "episode: 442/1000, score: 161, epsilon: 0.11\n",
      "episode: 443/1000, score: 199, epsilon: 0.11\n",
      "episode: 444/1000, score: 80, epsilon: 0.11\n",
      "episode: 445/1000, score: 199, epsilon: 0.11\n",
      "episode: 446/1000, score: 199, epsilon: 0.11\n",
      "episode: 447/1000, score: 199, epsilon: 0.11\n",
      "episode: 448/1000, score: 199, epsilon: 0.11\n",
      "episode: 449/1000, score: 186, epsilon: 0.11\n",
      "episode: 450/1000, score: 17, epsilon: 0.11\n",
      "episode: 451/1000, score: 138, epsilon: 0.1\n",
      "episode: 452/1000, score: 143, epsilon: 0.1\n",
      "episode: 453/1000, score: 199, epsilon: 0.1\n",
      "episode: 454/1000, score: 199, epsilon: 0.1\n",
      "episode: 455/1000, score: 199, epsilon: 0.1\n",
      "episode: 456/1000, score: 199, epsilon: 0.1\n",
      "episode: 457/1000, score: 199, epsilon: 0.1\n",
      "episode: 458/1000, score: 157, epsilon: 0.1\n",
      "episode: 459/1000, score: 199, epsilon: 0.1\n",
      "episode: 460/1000, score: 137, epsilon: 0.1\n",
      "episode: 461/1000, score: 199, epsilon: 0.1\n",
      "episode: 462/1000, score: 199, epsilon: 0.099\n",
      "episode: 463/1000, score: 26, epsilon: 0.099\n",
      "episode: 464/1000, score: 103, epsilon: 0.098\n",
      "episode: 465/1000, score: 140, epsilon: 0.098\n",
      "episode: 466/1000, score: 186, epsilon: 0.097\n",
      "episode: 467/1000, score: 171, epsilon: 0.097\n",
      "episode: 468/1000, score: 156, epsilon: 0.096\n",
      "episode: 469/1000, score: 199, epsilon: 0.096\n",
      "episode: 470/1000, score: 199, epsilon: 0.095\n",
      "episode: 471/1000, score: 199, epsilon: 0.095\n",
      "episode: 472/1000, score: 199, epsilon: 0.094\n",
      "episode: 473/1000, score: 199, epsilon: 0.094\n",
      "episode: 474/1000, score: 187, epsilon: 0.093\n",
      "episode: 475/1000, score: 199, epsilon: 0.093\n",
      "episode: 476/1000, score: 199, epsilon: 0.092\n",
      "episode: 477/1000, score: 199, epsilon: 0.092\n",
      "episode: 478/1000, score: 199, epsilon: 0.092\n",
      "episode: 479/1000, score: 199, epsilon: 0.091\n",
      "episode: 480/1000, score: 199, epsilon: 0.091\n",
      "episode: 481/1000, score: 199, epsilon: 0.09\n",
      "episode: 482/1000, score: 199, epsilon: 0.09\n",
      "episode: 483/1000, score: 199, epsilon: 0.089\n",
      "episode: 484/1000, score: 199, epsilon: 0.089\n",
      "episode: 485/1000, score: 199, epsilon: 0.088\n",
      "episode: 486/1000, score: 199, epsilon: 0.088\n",
      "episode: 487/1000, score: 199, epsilon: 0.088\n",
      "episode: 488/1000, score: 199, epsilon: 0.087\n",
      "episode: 489/1000, score: 199, epsilon: 0.087\n",
      "episode: 490/1000, score: 199, epsilon: 0.086\n",
      "episode: 491/1000, score: 199, epsilon: 0.086\n",
      "episode: 492/1000, score: 199, epsilon: 0.085\n",
      "episode: 493/1000, score: 199, epsilon: 0.085\n",
      "episode: 494/1000, score: 107, epsilon: 0.084\n",
      "episode: 495/1000, score: 149, epsilon: 0.084\n",
      "episode: 496/1000, score: 199, epsilon: 0.084\n",
      "episode: 497/1000, score: 199, epsilon: 0.083\n",
      "episode: 498/1000, score: 102, epsilon: 0.083\n",
      "episode: 499/1000, score: 199, epsilon: 0.082\n",
      "episode: 500/1000, score: 199, epsilon: 0.082\n",
      "episode: 501/1000, score: 190, epsilon: 0.082\n",
      "episode: 502/1000, score: 199, epsilon: 0.081\n",
      "episode: 503/1000, score: 199, epsilon: 0.081\n",
      "episode: 504/1000, score: 196, epsilon: 0.08\n",
      "episode: 505/1000, score: 168, epsilon: 0.08\n",
      "episode: 506/1000, score: 174, epsilon: 0.08\n",
      "episode: 507/1000, score: 199, epsilon: 0.079\n",
      "episode: 508/1000, score: 199, epsilon: 0.079\n",
      "episode: 509/1000, score: 196, epsilon: 0.078\n",
      "episode: 510/1000, score: 126, epsilon: 0.078\n",
      "episode: 511/1000, score: 179, epsilon: 0.078\n",
      "episode: 512/1000, score: 199, epsilon: 0.077\n",
      "episode: 513/1000, score: 199, epsilon: 0.077\n",
      "episode: 514/1000, score: 199, epsilon: 0.076\n",
      "episode: 515/1000, score: 199, epsilon: 0.076\n",
      "episode: 516/1000, score: 199, epsilon: 0.076\n",
      "episode: 517/1000, score: 199, epsilon: 0.075\n",
      "episode: 518/1000, score: 199, epsilon: 0.075\n",
      "episode: 519/1000, score: 199, epsilon: 0.075\n",
      "episode: 520/1000, score: 199, epsilon: 0.074\n",
      "episode: 521/1000, score: 199, epsilon: 0.074\n",
      "episode: 522/1000, score: 199, epsilon: 0.073\n",
      "episode: 523/1000, score: 199, epsilon: 0.073\n",
      "episode: 524/1000, score: 199, epsilon: 0.073\n",
      "episode: 525/1000, score: 199, epsilon: 0.072\n",
      "episode: 526/1000, score: 199, epsilon: 0.072\n",
      "episode: 527/1000, score: 199, epsilon: 0.072\n",
      "episode: 528/1000, score: 199, epsilon: 0.071\n",
      "episode: 529/1000, score: 199, epsilon: 0.071\n",
      "episode: 530/1000, score: 199, epsilon: 0.071\n",
      "episode: 531/1000, score: 199, epsilon: 0.07\n",
      "episode: 532/1000, score: 149, epsilon: 0.07\n",
      "episode: 533/1000, score: 199, epsilon: 0.069\n",
      "episode: 534/1000, score: 199, epsilon: 0.069\n",
      "episode: 535/1000, score: 199, epsilon: 0.069\n",
      "episode: 536/1000, score: 199, epsilon: 0.068\n",
      "episode: 537/1000, score: 199, epsilon: 0.068\n",
      "episode: 538/1000, score: 199, epsilon: 0.068\n",
      "episode: 539/1000, score: 199, epsilon: 0.067\n",
      "episode: 540/1000, score: 199, epsilon: 0.067\n",
      "episode: 541/1000, score: 199, epsilon: 0.067\n",
      "episode: 542/1000, score: 199, epsilon: 0.066\n",
      "episode: 543/1000, score: 199, epsilon: 0.066\n",
      "episode: 544/1000, score: 199, epsilon: 0.066\n",
      "episode: 545/1000, score: 199, epsilon: 0.065\n",
      "episode: 546/1000, score: 199, epsilon: 0.065\n",
      "episode: 547/1000, score: 199, epsilon: 0.065\n",
      "episode: 548/1000, score: 26, epsilon: 0.064\n",
      "episode: 549/1000, score: 199, epsilon: 0.064\n",
      "episode: 550/1000, score: 199, epsilon: 0.064\n",
      "episode: 551/1000, score: 199, epsilon: 0.063\n",
      "episode: 552/1000, score: 199, epsilon: 0.063\n",
      "episode: 553/1000, score: 199, epsilon: 0.063\n",
      "episode: 554/1000, score: 199, epsilon: 0.063\n",
      "episode: 555/1000, score: 199, epsilon: 0.062\n",
      "episode: 556/1000, score: 199, epsilon: 0.062\n",
      "episode: 557/1000, score: 199, epsilon: 0.062\n",
      "episode: 558/1000, score: 199, epsilon: 0.061\n",
      "episode: 559/1000, score: 199, epsilon: 0.061\n",
      "episode: 560/1000, score: 199, epsilon: 0.061\n",
      "episode: 561/1000, score: 199, epsilon: 0.06\n",
      "episode: 562/1000, score: 199, epsilon: 0.06\n",
      "episode: 563/1000, score: 199, epsilon: 0.06\n",
      "episode: 564/1000, score: 199, epsilon: 0.059\n",
      "episode: 565/1000, score: 199, epsilon: 0.059\n",
      "episode: 566/1000, score: 199, epsilon: 0.059\n",
      "episode: 567/1000, score: 199, epsilon: 0.059\n",
      "episode: 568/1000, score: 199, epsilon: 0.058\n",
      "episode: 569/1000, score: 199, epsilon: 0.058\n",
      "episode: 570/1000, score: 199, epsilon: 0.058\n",
      "episode: 571/1000, score: 199, epsilon: 0.057\n",
      "episode: 572/1000, score: 199, epsilon: 0.057\n",
      "episode: 573/1000, score: 160, epsilon: 0.057\n",
      "episode: 574/1000, score: 199, epsilon: 0.057\n",
      "episode: 575/1000, score: 199, epsilon: 0.056\n",
      "episode: 576/1000, score: 199, epsilon: 0.056\n",
      "episode: 577/1000, score: 199, epsilon: 0.056\n",
      "episode: 578/1000, score: 103, epsilon: 0.055\n",
      "episode: 579/1000, score: 111, epsilon: 0.055\n",
      "episode: 580/1000, score: 199, epsilon: 0.055\n",
      "episode: 581/1000, score: 199, epsilon: 0.055\n",
      "episode: 582/1000, score: 199, epsilon: 0.054\n",
      "episode: 583/1000, score: 199, epsilon: 0.054\n",
      "episode: 584/1000, score: 199, epsilon: 0.054\n",
      "episode: 585/1000, score: 199, epsilon: 0.054\n",
      "episode: 586/1000, score: 199, epsilon: 0.053\n",
      "episode: 587/1000, score: 199, epsilon: 0.053\n",
      "episode: 588/1000, score: 199, epsilon: 0.053\n",
      "episode: 589/1000, score: 166, epsilon: 0.052\n",
      "episode: 590/1000, score: 97, epsilon: 0.052\n",
      "episode: 591/1000, score: 30, epsilon: 0.052\n",
      "episode: 592/1000, score: 176, epsilon: 0.052\n",
      "episode: 593/1000, score: 189, epsilon: 0.051\n",
      "episode: 594/1000, score: 194, epsilon: 0.051\n",
      "episode: 595/1000, score: 196, epsilon: 0.051\n",
      "episode: 596/1000, score: 199, epsilon: 0.051\n",
      "episode: 597/1000, score: 188, epsilon: 0.05\n",
      "episode: 598/1000, score: 166, epsilon: 0.05\n",
      "episode: 599/1000, score: 188, epsilon: 0.05\n",
      "episode: 600/1000, score: 178, epsilon: 0.05\n",
      "episode: 601/1000, score: 199, epsilon: 0.049\n",
      "episode: 602/1000, score: 122, epsilon: 0.049\n",
      "episode: 603/1000, score: 199, epsilon: 0.049\n",
      "episode: 604/1000, score: 199, epsilon: 0.049\n",
      "episode: 605/1000, score: 199, epsilon: 0.048\n",
      "episode: 606/1000, score: 199, epsilon: 0.048\n",
      "episode: 607/1000, score: 199, epsilon: 0.048\n",
      "episode: 608/1000, score: 124, epsilon: 0.048\n",
      "episode: 609/1000, score: 193, epsilon: 0.047\n",
      "episode: 610/1000, score: 199, epsilon: 0.047\n",
      "episode: 611/1000, score: 97, epsilon: 0.047\n",
      "episode: 612/1000, score: 134, epsilon: 0.047\n",
      "episode: 613/1000, score: 199, epsilon: 0.047\n",
      "episode: 614/1000, score: 190, epsilon: 0.046\n",
      "episode: 615/1000, score: 188, epsilon: 0.046\n",
      "episode: 616/1000, score: 199, epsilon: 0.046\n",
      "episode: 617/1000, score: 130, epsilon: 0.046\n",
      "episode: 618/1000, score: 199, epsilon: 0.045\n",
      "episode: 619/1000, score: 194, epsilon: 0.045\n",
      "episode: 620/1000, score: 188, epsilon: 0.045\n",
      "episode: 621/1000, score: 195, epsilon: 0.045\n",
      "episode: 622/1000, score: 185, epsilon: 0.044\n",
      "episode: 623/1000, score: 199, epsilon: 0.044\n",
      "episode: 624/1000, score: 168, epsilon: 0.044\n",
      "episode: 625/1000, score: 198, epsilon: 0.044\n",
      "episode: 626/1000, score: 199, epsilon: 0.044\n",
      "episode: 627/1000, score: 199, epsilon: 0.043\n",
      "episode: 628/1000, score: 108, epsilon: 0.043\n",
      "episode: 629/1000, score: 187, epsilon: 0.043\n",
      "episode: 630/1000, score: 199, epsilon: 0.043\n",
      "episode: 631/1000, score: 142, epsilon: 0.043\n",
      "episode: 632/1000, score: 170, epsilon: 0.042\n",
      "episode: 633/1000, score: 136, epsilon: 0.042\n",
      "episode: 634/1000, score: 159, epsilon: 0.042\n",
      "episode: 635/1000, score: 161, epsilon: 0.042\n",
      "episode: 636/1000, score: 107, epsilon: 0.041\n",
      "episode: 637/1000, score: 23, epsilon: 0.041\n",
      "episode: 638/1000, score: 126, epsilon: 0.041\n",
      "episode: 639/1000, score: 141, epsilon: 0.041\n",
      "episode: 640/1000, score: 183, epsilon: 0.041\n",
      "episode: 641/1000, score: 177, epsilon: 0.04\n",
      "episode: 642/1000, score: 154, epsilon: 0.04\n",
      "episode: 643/1000, score: 156, epsilon: 0.04\n",
      "episode: 644/1000, score: 176, epsilon: 0.04\n",
      "episode: 645/1000, score: 135, epsilon: 0.04\n",
      "episode: 646/1000, score: 130, epsilon: 0.039\n",
      "episode: 647/1000, score: 136, epsilon: 0.039\n",
      "episode: 648/1000, score: 149, epsilon: 0.039\n",
      "episode: 649/1000, score: 156, epsilon: 0.039\n",
      "episode: 650/1000, score: 155, epsilon: 0.039\n",
      "episode: 651/1000, score: 125, epsilon: 0.038\n",
      "episode: 652/1000, score: 121, epsilon: 0.038\n",
      "episode: 653/1000, score: 119, epsilon: 0.038\n",
      "episode: 654/1000, score: 122, epsilon: 0.038\n",
      "episode: 655/1000, score: 125, epsilon: 0.038\n",
      "episode: 656/1000, score: 137, epsilon: 0.038\n",
      "episode: 657/1000, score: 128, epsilon: 0.037\n",
      "episode: 658/1000, score: 117, epsilon: 0.037\n",
      "episode: 659/1000, score: 119, epsilon: 0.037\n",
      "episode: 660/1000, score: 142, epsilon: 0.037\n",
      "episode: 661/1000, score: 14, epsilon: 0.037\n",
      "episode: 662/1000, score: 98, epsilon: 0.036\n",
      "episode: 663/1000, score: 111, epsilon: 0.036\n",
      "episode: 664/1000, score: 17, epsilon: 0.036\n",
      "episode: 665/1000, score: 102, epsilon: 0.036\n",
      "episode: 666/1000, score: 13, epsilon: 0.036\n",
      "episode: 667/1000, score: 99, epsilon: 0.035\n",
      "episode: 668/1000, score: 102, epsilon: 0.035\n",
      "episode: 669/1000, score: 98, epsilon: 0.035\n",
      "episode: 670/1000, score: 91, epsilon: 0.035\n",
      "episode: 671/1000, score: 87, epsilon: 0.035\n",
      "episode: 672/1000, score: 97, epsilon: 0.035\n",
      "episode: 673/1000, score: 74, epsilon: 0.034\n",
      "episode: 674/1000, score: 91, epsilon: 0.034\n",
      "episode: 675/1000, score: 20, epsilon: 0.034\n",
      "episode: 676/1000, score: 76, epsilon: 0.034\n",
      "episode: 677/1000, score: 88, epsilon: 0.034\n",
      "episode: 678/1000, score: 78, epsilon: 0.034\n",
      "episode: 679/1000, score: 90, epsilon: 0.033\n",
      "episode: 680/1000, score: 96, epsilon: 0.033\n",
      "episode: 681/1000, score: 77, epsilon: 0.033\n",
      "episode: 682/1000, score: 82, epsilon: 0.033\n",
      "episode: 683/1000, score: 78, epsilon: 0.033\n",
      "episode: 684/1000, score: 90, epsilon: 0.033\n",
      "episode: 685/1000, score: 12, epsilon: 0.032\n",
      "episode: 686/1000, score: 63, epsilon: 0.032\n",
      "episode: 687/1000, score: 81, epsilon: 0.032\n",
      "episode: 688/1000, score: 79, epsilon: 0.032\n",
      "episode: 689/1000, score: 199, epsilon: 0.032\n",
      "episode: 690/1000, score: 17, epsilon: 0.032\n",
      "episode: 691/1000, score: 74, epsilon: 0.031\n",
      "episode: 692/1000, score: 96, epsilon: 0.031\n",
      "episode: 693/1000, score: 129, epsilon: 0.031\n",
      "episode: 694/1000, score: 199, epsilon: 0.031\n",
      "episode: 695/1000, score: 131, epsilon: 0.031\n",
      "episode: 696/1000, score: 199, epsilon: 0.031\n",
      "episode: 697/1000, score: 107, epsilon: 0.031\n",
      "episode: 698/1000, score: 89, epsilon: 0.03\n",
      "episode: 699/1000, score: 131, epsilon: 0.03\n",
      "episode: 700/1000, score: 195, epsilon: 0.03\n",
      "episode: 701/1000, score: 75, epsilon: 0.03\n",
      "episode: 702/1000, score: 114, epsilon: 0.03\n",
      "episode: 703/1000, score: 87, epsilon: 0.03\n",
      "episode: 704/1000, score: 101, epsilon: 0.029\n",
      "episode: 705/1000, score: 96, epsilon: 0.029\n",
      "episode: 706/1000, score: 115, epsilon: 0.029\n",
      "episode: 707/1000, score: 134, epsilon: 0.029\n",
      "episode: 708/1000, score: 100, epsilon: 0.029\n",
      "episode: 709/1000, score: 121, epsilon: 0.029\n",
      "episode: 710/1000, score: 165, epsilon: 0.029\n",
      "episode: 711/1000, score: 146, epsilon: 0.028\n",
      "episode: 712/1000, score: 181, epsilon: 0.028\n",
      "episode: 713/1000, score: 199, epsilon: 0.028\n",
      "episode: 714/1000, score: 199, epsilon: 0.028\n",
      "episode: 715/1000, score: 199, epsilon: 0.028\n",
      "episode: 716/1000, score: 181, epsilon: 0.028\n",
      "episode: 717/1000, score: 161, epsilon: 0.028\n",
      "episode: 718/1000, score: 199, epsilon: 0.027\n",
      "episode: 719/1000, score: 171, epsilon: 0.027\n",
      "episode: 720/1000, score: 173, epsilon: 0.027\n",
      "episode: 721/1000, score: 85, epsilon: 0.027\n",
      "episode: 722/1000, score: 109, epsilon: 0.027\n",
      "episode: 723/1000, score: 146, epsilon: 0.027\n",
      "episode: 724/1000, score: 135, epsilon: 0.027\n",
      "episode: 725/1000, score: 140, epsilon: 0.027\n",
      "episode: 726/1000, score: 129, epsilon: 0.026\n",
      "episode: 727/1000, score: 91, epsilon: 0.026\n",
      "episode: 728/1000, score: 107, epsilon: 0.026\n",
      "episode: 729/1000, score: 139, epsilon: 0.026\n",
      "episode: 730/1000, score: 132, epsilon: 0.026\n",
      "episode: 731/1000, score: 128, epsilon: 0.026\n",
      "episode: 732/1000, score: 123, epsilon: 0.026\n",
      "episode: 733/1000, score: 149, epsilon: 0.025\n",
      "episode: 734/1000, score: 101, epsilon: 0.025\n",
      "episode: 735/1000, score: 97, epsilon: 0.025\n",
      "episode: 736/1000, score: 131, epsilon: 0.025\n",
      "episode: 737/1000, score: 158, epsilon: 0.025\n",
      "episode: 738/1000, score: 199, epsilon: 0.025\n",
      "episode: 739/1000, score: 157, epsilon: 0.025\n",
      "episode: 740/1000, score: 199, epsilon: 0.025\n",
      "episode: 741/1000, score: 180, epsilon: 0.024\n",
      "episode: 742/1000, score: 199, epsilon: 0.024\n",
      "episode: 743/1000, score: 199, epsilon: 0.024\n",
      "episode: 744/1000, score: 162, epsilon: 0.024\n",
      "episode: 745/1000, score: 119, epsilon: 0.024\n",
      "episode: 746/1000, score: 138, epsilon: 0.024\n",
      "episode: 747/1000, score: 144, epsilon: 0.024\n",
      "episode: 748/1000, score: 176, epsilon: 0.024\n",
      "episode: 749/1000, score: 199, epsilon: 0.024\n",
      "episode: 750/1000, score: 57, epsilon: 0.023\n",
      "episode: 751/1000, score: 199, epsilon: 0.023\n",
      "episode: 752/1000, score: 179, epsilon: 0.023\n",
      "episode: 753/1000, score: 199, epsilon: 0.023\n",
      "episode: 754/1000, score: 179, epsilon: 0.023\n",
      "episode: 755/1000, score: 199, epsilon: 0.023\n",
      "episode: 756/1000, score: 159, epsilon: 0.023\n",
      "episode: 757/1000, score: 199, epsilon: 0.023\n",
      "episode: 758/1000, score: 199, epsilon: 0.022\n",
      "episode: 759/1000, score: 199, epsilon: 0.022\n",
      "episode: 760/1000, score: 199, epsilon: 0.022\n",
      "episode: 761/1000, score: 163, epsilon: 0.022\n",
      "episode: 762/1000, score: 199, epsilon: 0.022\n",
      "episode: 763/1000, score: 199, epsilon: 0.022\n",
      "episode: 764/1000, score: 199, epsilon: 0.022\n",
      "episode: 765/1000, score: 144, epsilon: 0.022\n",
      "episode: 766/1000, score: 140, epsilon: 0.022\n",
      "episode: 767/1000, score: 199, epsilon: 0.022\n",
      "episode: 768/1000, score: 169, epsilon: 0.021\n",
      "episode: 769/1000, score: 199, epsilon: 0.021\n",
      "episode: 770/1000, score: 50, epsilon: 0.021\n",
      "episode: 771/1000, score: 102, epsilon: 0.021\n",
      "episode: 772/1000, score: 167, epsilon: 0.021\n",
      "episode: 773/1000, score: 199, epsilon: 0.021\n",
      "episode: 774/1000, score: 176, epsilon: 0.021\n",
      "episode: 775/1000, score: 199, epsilon: 0.021\n",
      "episode: 776/1000, score: 199, epsilon: 0.021\n",
      "episode: 777/1000, score: 199, epsilon: 0.02\n",
      "episode: 778/1000, score: 199, epsilon: 0.02\n",
      "episode: 779/1000, score: 58, epsilon: 0.02\n",
      "episode: 780/1000, score: 74, epsilon: 0.02\n",
      "episode: 781/1000, score: 177, epsilon: 0.02\n",
      "episode: 782/1000, score: 103, epsilon: 0.02\n",
      "episode: 783/1000, score: 199, epsilon: 0.02\n",
      "episode: 784/1000, score: 189, epsilon: 0.02\n",
      "episode: 785/1000, score: 199, epsilon: 0.02\n",
      "episode: 786/1000, score: 199, epsilon: 0.02\n",
      "episode: 787/1000, score: 153, epsilon: 0.019\n",
      "episode: 788/1000, score: 199, epsilon: 0.019\n",
      "episode: 789/1000, score: 85, epsilon: 0.019\n",
      "episode: 790/1000, score: 179, epsilon: 0.019\n",
      "episode: 791/1000, score: 127, epsilon: 0.019\n",
      "episode: 792/1000, score: 129, epsilon: 0.019\n",
      "episode: 793/1000, score: 156, epsilon: 0.019\n",
      "episode: 794/1000, score: 183, epsilon: 0.019\n",
      "episode: 795/1000, score: 199, epsilon: 0.019\n",
      "episode: 796/1000, score: 156, epsilon: 0.019\n",
      "episode: 797/1000, score: 199, epsilon: 0.019\n",
      "episode: 798/1000, score: 162, epsilon: 0.018\n",
      "episode: 799/1000, score: 187, epsilon: 0.018\n",
      "episode: 800/1000, score: 172, epsilon: 0.018\n",
      "episode: 801/1000, score: 199, epsilon: 0.018\n",
      "episode: 802/1000, score: 199, epsilon: 0.018\n",
      "episode: 803/1000, score: 199, epsilon: 0.018\n",
      "episode: 804/1000, score: 153, epsilon: 0.018\n",
      "episode: 805/1000, score: 197, epsilon: 0.018\n",
      "episode: 806/1000, score: 190, epsilon: 0.018\n",
      "episode: 807/1000, score: 199, epsilon: 0.018\n",
      "episode: 808/1000, score: 199, epsilon: 0.018\n",
      "episode: 809/1000, score: 199, epsilon: 0.017\n",
      "episode: 810/1000, score: 171, epsilon: 0.017\n",
      "episode: 811/1000, score: 199, epsilon: 0.017\n",
      "episode: 812/1000, score: 199, epsilon: 0.017\n",
      "episode: 813/1000, score: 199, epsilon: 0.017\n",
      "episode: 814/1000, score: 149, epsilon: 0.017\n",
      "episode: 815/1000, score: 199, epsilon: 0.017\n",
      "episode: 816/1000, score: 199, epsilon: 0.017\n",
      "episode: 817/1000, score: 199, epsilon: 0.017\n",
      "episode: 818/1000, score: 199, epsilon: 0.017\n",
      "episode: 819/1000, score: 199, epsilon: 0.017\n",
      "episode: 820/1000, score: 199, epsilon: 0.016\n",
      "episode: 821/1000, score: 199, epsilon: 0.016\n",
      "episode: 822/1000, score: 199, epsilon: 0.016\n",
      "episode: 823/1000, score: 123, epsilon: 0.016\n",
      "episode: 824/1000, score: 124, epsilon: 0.016\n",
      "episode: 825/1000, score: 199, epsilon: 0.016\n",
      "episode: 826/1000, score: 103, epsilon: 0.016\n",
      "episode: 827/1000, score: 196, epsilon: 0.016\n",
      "episode: 828/1000, score: 199, epsilon: 0.016\n",
      "episode: 829/1000, score: 199, epsilon: 0.016\n",
      "episode: 830/1000, score: 199, epsilon: 0.016\n",
      "episode: 831/1000, score: 199, epsilon: 0.016\n",
      "episode: 832/1000, score: 199, epsilon: 0.016\n",
      "episode: 833/1000, score: 199, epsilon: 0.015\n",
      "episode: 834/1000, score: 199, epsilon: 0.015\n",
      "episode: 835/1000, score: 153, epsilon: 0.015\n",
      "episode: 836/1000, score: 158, epsilon: 0.015\n",
      "episode: 837/1000, score: 199, epsilon: 0.015\n",
      "episode: 838/1000, score: 199, epsilon: 0.015\n",
      "episode: 839/1000, score: 199, epsilon: 0.015\n",
      "episode: 840/1000, score: 199, epsilon: 0.015\n",
      "episode: 841/1000, score: 199, epsilon: 0.015\n",
      "episode: 842/1000, score: 199, epsilon: 0.015\n",
      "episode: 843/1000, score: 199, epsilon: 0.015\n",
      "episode: 844/1000, score: 199, epsilon: 0.015\n",
      "episode: 845/1000, score: 199, epsilon: 0.015\n",
      "episode: 846/1000, score: 199, epsilon: 0.014\n",
      "episode: 847/1000, score: 199, epsilon: 0.014\n",
      "episode: 848/1000, score: 199, epsilon: 0.014\n",
      "episode: 849/1000, score: 199, epsilon: 0.014\n",
      "episode: 850/1000, score: 199, epsilon: 0.014\n",
      "episode: 851/1000, score: 199, epsilon: 0.014\n",
      "episode: 852/1000, score: 199, epsilon: 0.014\n",
      "episode: 853/1000, score: 199, epsilon: 0.014\n",
      "episode: 854/1000, score: 199, epsilon: 0.014\n",
      "episode: 855/1000, score: 114, epsilon: 0.014\n",
      "episode: 856/1000, score: 107, epsilon: 0.014\n",
      "episode: 857/1000, score: 199, epsilon: 0.014\n",
      "episode: 858/1000, score: 199, epsilon: 0.014\n",
      "episode: 859/1000, score: 199, epsilon: 0.014\n",
      "episode: 860/1000, score: 91, epsilon: 0.013\n",
      "episode: 861/1000, score: 136, epsilon: 0.013\n",
      "episode: 862/1000, score: 184, epsilon: 0.013\n",
      "episode: 863/1000, score: 131, epsilon: 0.013\n",
      "episode: 864/1000, score: 199, epsilon: 0.013\n",
      "episode: 865/1000, score: 199, epsilon: 0.013\n",
      "episode: 866/1000, score: 150, epsilon: 0.013\n",
      "episode: 867/1000, score: 199, epsilon: 0.013\n",
      "episode: 868/1000, score: 87, epsilon: 0.013\n",
      "episode: 869/1000, score: 109, epsilon: 0.013\n",
      "episode: 870/1000, score: 199, epsilon: 0.013\n",
      "episode: 871/1000, score: 199, epsilon: 0.013\n",
      "episode: 872/1000, score: 117, epsilon: 0.013\n",
      "episode: 873/1000, score: 123, epsilon: 0.013\n",
      "episode: 874/1000, score: 199, epsilon: 0.013\n",
      "episode: 875/1000, score: 199, epsilon: 0.013\n",
      "episode: 876/1000, score: 199, epsilon: 0.012\n",
      "episode: 877/1000, score: 93, epsilon: 0.012\n",
      "episode: 878/1000, score: 125, epsilon: 0.012\n",
      "episode: 879/1000, score: 117, epsilon: 0.012\n",
      "episode: 880/1000, score: 101, epsilon: 0.012\n",
      "episode: 881/1000, score: 119, epsilon: 0.012\n",
      "episode: 882/1000, score: 196, epsilon: 0.012\n",
      "episode: 883/1000, score: 199, epsilon: 0.012\n",
      "episode: 884/1000, score: 199, epsilon: 0.012\n",
      "episode: 885/1000, score: 199, epsilon: 0.012\n",
      "episode: 886/1000, score: 199, epsilon: 0.012\n",
      "episode: 887/1000, score: 199, epsilon: 0.012\n",
      "episode: 888/1000, score: 199, epsilon: 0.012\n",
      "episode: 889/1000, score: 199, epsilon: 0.012\n",
      "episode: 890/1000, score: 183, epsilon: 0.012\n",
      "episode: 891/1000, score: 199, epsilon: 0.012\n",
      "episode: 892/1000, score: 199, epsilon: 0.011\n",
      "episode: 893/1000, score: 199, epsilon: 0.011\n",
      "episode: 894/1000, score: 199, epsilon: 0.011\n",
      "episode: 895/1000, score: 196, epsilon: 0.011\n",
      "episode: 896/1000, score: 199, epsilon: 0.011\n",
      "episode: 897/1000, score: 199, epsilon: 0.011\n",
      "episode: 898/1000, score: 137, epsilon: 0.011\n",
      "episode: 899/1000, score: 199, epsilon: 0.011\n",
      "episode: 900/1000, score: 180, epsilon: 0.011\n",
      "episode: 901/1000, score: 171, epsilon: 0.011\n",
      "episode: 902/1000, score: 156, epsilon: 0.011\n",
      "episode: 903/1000, score: 180, epsilon: 0.011\n",
      "episode: 904/1000, score: 199, epsilon: 0.011\n",
      "episode: 905/1000, score: 199, epsilon: 0.011\n",
      "episode: 906/1000, score: 151, epsilon: 0.011\n",
      "episode: 907/1000, score: 142, epsilon: 0.011\n",
      "episode: 908/1000, score: 138, epsilon: 0.011\n",
      "episode: 909/1000, score: 126, epsilon: 0.011\n",
      "episode: 910/1000, score: 100, epsilon: 0.01\n",
      "episode: 911/1000, score: 129, epsilon: 0.01\n",
      "episode: 912/1000, score: 160, epsilon: 0.01\n",
      "episode: 913/1000, score: 117, epsilon: 0.01\n",
      "episode: 914/1000, score: 133, epsilon: 0.01\n",
      "episode: 915/1000, score: 133, epsilon: 0.01\n",
      "episode: 916/1000, score: 127, epsilon: 0.01\n",
      "episode: 917/1000, score: 107, epsilon: 0.01\n",
      "episode: 918/1000, score: 89, epsilon: 0.01\n",
      "episode: 919/1000, score: 103, epsilon: 0.01\n",
      "episode: 920/1000, score: 121, epsilon: 0.01\n",
      "episode: 921/1000, score: 116, epsilon: 0.01\n",
      "episode: 922/1000, score: 147, epsilon: 0.01\n",
      "episode: 923/1000, score: 89, epsilon: 0.01\n",
      "episode: 924/1000, score: 97, epsilon: 0.01\n",
      "episode: 925/1000, score: 124, epsilon: 0.01\n",
      "episode: 926/1000, score: 124, epsilon: 0.01\n",
      "episode: 927/1000, score: 98, epsilon: 0.01\n",
      "episode: 928/1000, score: 87, epsilon: 0.01\n",
      "episode: 929/1000, score: 144, epsilon: 0.01\n",
      "episode: 930/1000, score: 184, epsilon: 0.01\n",
      "episode: 931/1000, score: 199, epsilon: 0.01\n",
      "episode: 932/1000, score: 199, epsilon: 0.01\n",
      "episode: 933/1000, score: 199, epsilon: 0.01\n",
      "episode: 934/1000, score: 191, epsilon: 0.01\n",
      "episode: 935/1000, score: 176, epsilon: 0.01\n",
      "episode: 936/1000, score: 183, epsilon: 0.01\n",
      "episode: 937/1000, score: 171, epsilon: 0.01\n",
      "episode: 938/1000, score: 199, epsilon: 0.01\n",
      "episode: 939/1000, score: 198, epsilon: 0.01\n",
      "episode: 940/1000, score: 137, epsilon: 0.01\n",
      "episode: 941/1000, score: 185, epsilon: 0.01\n",
      "episode: 942/1000, score: 199, epsilon: 0.01\n",
      "episode: 943/1000, score: 185, epsilon: 0.01\n",
      "episode: 944/1000, score: 132, epsilon: 0.01\n",
      "episode: 945/1000, score: 153, epsilon: 0.01\n",
      "episode: 946/1000, score: 199, epsilon: 0.01\n",
      "episode: 947/1000, score: 199, epsilon: 0.01\n",
      "episode: 948/1000, score: 199, epsilon: 0.01\n",
      "episode: 949/1000, score: 199, epsilon: 0.01\n",
      "episode: 950/1000, score: 131, epsilon: 0.01\n",
      "episode: 951/1000, score: 199, epsilon: 0.01\n",
      "episode: 952/1000, score: 199, epsilon: 0.01\n",
      "episode: 953/1000, score: 199, epsilon: 0.01\n",
      "episode: 954/1000, score: 199, epsilon: 0.01\n",
      "episode: 955/1000, score: 199, epsilon: 0.01\n",
      "episode: 956/1000, score: 199, epsilon: 0.01\n",
      "episode: 957/1000, score: 126, epsilon: 0.01\n",
      "episode: 958/1000, score: 199, epsilon: 0.01\n",
      "episode: 959/1000, score: 126, epsilon: 0.01\n",
      "episode: 960/1000, score: 199, epsilon: 0.01\n",
      "episode: 961/1000, score: 199, epsilon: 0.01\n",
      "episode: 962/1000, score: 167, epsilon: 0.01\n",
      "episode: 963/1000, score: 199, epsilon: 0.01\n",
      "episode: 964/1000, score: 199, epsilon: 0.01\n",
      "episode: 965/1000, score: 199, epsilon: 0.01\n",
      "episode: 966/1000, score: 199, epsilon: 0.01\n",
      "episode: 967/1000, score: 199, epsilon: 0.01\n",
      "episode: 968/1000, score: 199, epsilon: 0.01\n",
      "episode: 969/1000, score: 199, epsilon: 0.01\n",
      "episode: 970/1000, score: 199, epsilon: 0.01\n",
      "episode: 971/1000, score: 199, epsilon: 0.01\n",
      "episode: 972/1000, score: 199, epsilon: 0.01\n",
      "episode: 973/1000, score: 199, epsilon: 0.01\n",
      "episode: 974/1000, score: 199, epsilon: 0.01\n",
      "episode: 975/1000, score: 199, epsilon: 0.01\n",
      "episode: 976/1000, score: 199, epsilon: 0.01\n",
      "episode: 977/1000, score: 199, epsilon: 0.01\n",
      "episode: 978/1000, score: 199, epsilon: 0.01\n",
      "episode: 979/1000, score: 199, epsilon: 0.01\n",
      "episode: 980/1000, score: 199, epsilon: 0.01\n",
      "episode: 981/1000, score: 199, epsilon: 0.01\n",
      "episode: 982/1000, score: 199, epsilon: 0.01\n",
      "episode: 983/1000, score: 199, epsilon: 0.01\n",
      "episode: 984/1000, score: 199, epsilon: 0.01\n",
      "episode: 985/1000, score: 199, epsilon: 0.01\n",
      "episode: 986/1000, score: 199, epsilon: 0.01\n",
      "episode: 987/1000, score: 199, epsilon: 0.01\n",
      "episode: 988/1000, score: 199, epsilon: 0.01\n",
      "episode: 989/1000, score: 131, epsilon: 0.01\n",
      "episode: 990/1000, score: 199, epsilon: 0.01\n",
      "episode: 991/1000, score: 199, epsilon: 0.01\n",
      "episode: 992/1000, score: 199, epsilon: 0.01\n",
      "episode: 993/1000, score: 199, epsilon: 0.01\n",
      "episode: 994/1000, score: 103, epsilon: 0.01\n",
      "episode: 995/1000, score: 199, epsilon: 0.01\n",
      "episode: 996/1000, score: 199, epsilon: 0.01\n",
      "episode: 997/1000, score: 199, epsilon: 0.01\n",
      "episode: 998/1000, score: 199, epsilon: 0.01\n",
      "episode: 999/1000, score: 199, epsilon: 0.01\n",
      "episode: 1000/1000, score: 199, epsilon: 0.01\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, n_episodes + 1): # iterate over episodes of gameplay\n",
    "    state = env.reset() # reset state at start of each new episode of the game\n",
    "    state = np.array(state[0])\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    done = False\n",
    "    time = 0 # time represents a frame of the episode; goal is to keep pole upright as long as possible\n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action = agent.act(state) # action is either 0 or 1 (move cart left or right); decide on one or other here\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action) # agent interacts with env, gets feedback; 4 state data points, e.g. cart position, cart velocity, pole angle, pile velocity\n",
    "        done = terminated or truncated\n",
    "        reward = reward + 1 if not done else -10 # reward +1 for each additional frame with pole upright, penalty of -10 if not\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done) # remember the previous timestep's state, actions, reward, etc.\n",
    "        state = next_state # set \"current state\" for upcoming iteration to the current next state\n",
    "        if done: # if episode ends:\n",
    "            print(\"episode: {}/{}, score: {}, epsilon: {:.2}\".format(e, n_episodes, time, agent.epsilon)) # print the episode's score and agent's epsilon\n",
    "        time += 1\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.train(batch_size) # train the agent by replaying the experiences of the episode\n",
    "    if e % 100 == 0:\n",
    "        agent.save(output_dir + '{:04d}'.format(e) + \".weights\" + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rMUA_MS7iHOX"
   },
   "outputs": [],
   "source": [
    "# saved agents can be loaded with agent.load(\"./path/filename.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      2.2.2\n",
      "asttokens                    3.0.0\n",
      "astunparse                   1.6.3\n",
      "cachetools                   5.5.2\n",
      "certifi                      2025.4.26\n",
      "charset-normalizer           3.4.2\n",
      "cloudpickle                  3.1.1\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.1\n",
      "debugpy                      1.8.11\n",
      "decorator                    5.1.1\n",
      "exceptiongroup               1.2.0\n",
      "executing                    0.8.3\n",
      "Farama-Notifications         0.0.4\n",
      "flatbuffers                  25.2.10\n",
      "gast                         0.4.0\n",
      "google-auth                  2.40.2\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.71.0\n",
      "gym                          0.26.2\n",
      "gym-notices                  0.0.8\n",
      "gymnasium                    1.1.1\n",
      "h5py                         3.13.0\n",
      "idna                         3.10\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.30.0\n",
      "jedi                         0.19.2\n",
      "jupyter_client               8.6.3\n",
      "jupyter_core                 5.7.2\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.8\n",
      "MarkupSafe                   3.0.2\n",
      "matplotlib-inline            0.1.6\n",
      "nest-asyncio                 1.6.0\n",
      "numpy                        1.21.3\n",
      "oauthlib                     3.2.2\n",
      "opt_einsum                   3.4.0\n",
      "packaging                    24.2\n",
      "parso                        0.8.4\n",
      "pip                          25.1\n",
      "platformdirs                 4.3.7\n",
      "prompt-toolkit               3.0.43\n",
      "protobuf                     3.19.6\n",
      "psutil                       5.9.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.6.1\n",
      "pyasn1_modules               0.4.2\n",
      "Pygments                     2.19.1\n",
      "python-dateutil              2.9.0.post0\n",
      "pywin32                      308\n",
      "pyzmq                        26.2.0\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            2.0.0\n",
      "rsa                          4.9.1\n",
      "setuptools                   78.1.1\n",
      "six                          1.17.0\n",
      "stack-data                   0.2.0\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.0\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    3.1.0\n",
      "tornado                      6.5\n",
      "traitlets                    5.14.3\n",
      "typing_extensions            4.12.2\n",
      "urllib3                      2.4.0\n",
      "wcwidth                      0.2.5\n",
      "Werkzeug                     3.1.3\n",
      "wheel                        0.45.1\n",
      "wrapt                        1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DQN_TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
